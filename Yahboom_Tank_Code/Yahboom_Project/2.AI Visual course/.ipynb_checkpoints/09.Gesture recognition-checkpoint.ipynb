{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Copyright (C): 2010-2020, Shenzhen Yahboom Tech  \n",
    "@Author: Liusen  \n",
    "@Date: 2020-02-24 11:10:02  \n",
    "@LastEditors: Liusen  \n",
    "@LastEditTime: 2020-02-24 11:10:02    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgr8 to jpeg format\n",
    "import enum\n",
    "import cv2\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the gesture recognition function part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import time\n",
    "import demjson\n",
    "import pygame \n",
    "from aip import AipBodyAnalysis\n",
    "from aip import AipSpeech\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "hand={'One':'one','Five':'five','Fist':'fist','Ok':'OK',\n",
    "      'Prayer':'pray','Congratulation':'congratulation','Honour':'honour',\n",
    "      'Heart_single':'heart_single','Thumb_up':'thumb_up','Thumb_down':'thumb_down',\n",
    "      'ILY':'i_love_you','Palm_up':'palm_up','Heart_1':'heart_one',\n",
    "      'Heart_2':'heart_two','Heart_3':'heart_three','Two':'two',\n",
    "      'Three':'three','Four':'four','Six':'six','Seven':'seven',\n",
    "      'Eight':'eight','Nine':'nine','Rock':'rock','Face':'face'}\n",
    "\n",
    "# Change the key below to your own key\n",
    "\"\"\"  Analysis of body APPID AK SK \"\"\"\n",
    "APP_ID = '18550528'\n",
    "API_KEY = 'K6PWqtiUTKYK1fYaz13O8E3i'\n",
    "SECRET_KEY = 'IDBUII1j6srF1XVNDX32I2WpuwBWczzK'\n",
    "\n",
    "\n",
    "\n",
    "#camera = PiCamera()\n",
    "client = AipBodyAnalysis(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "\n",
    "g_camera = cv2.VideoCapture(0)\n",
    "g_camera.set(3, 640)\n",
    "g_camera.set(4, 480)\n",
    "g_camera.set(5, 120)  #Set the frame rate\n",
    "g_camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "g_camera.set(cv2.CAP_PROP_BRIGHTNESS, 40) #Set brightness -64 - 64  0.0\n",
    "g_camera.set(cv2.CAP_PROP_CONTRAST, 50) #Set contrast  -64 - 64  2.0\n",
    "g_camera.set(cv2.CAP_PROP_EXPOSURE, 156) #Set exposure 1.0 - 5000  156.0\n",
    "\n",
    "ret, frame = g_camera.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the camera display component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg', width=600, height=500)  #Set the camera display component\n",
    "display(image_widget)   \n",
    "image_widget.value = bgr8_to_jpeg(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define conversion display Chinese function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20):\n",
    "    if (isinstance(img, numpy.ndarray)):  # Determine if OpenCV image type\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # Create an object that can draw on a given image\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # Font format\n",
    "    fontStyle = ImageFont.truetype(\n",
    "        \"simhei.ttf\", textSize, encoding=\"utf-8\")\n",
    "    # Draw text\n",
    "    draw.text((left, top), text, textColor, font=fontStyle)\n",
    "    # Convert back to OpenCV format\n",
    "    return cv2.cvtColor(numpy.asarray(img), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \"\"\"1.take a picture \"\"\"\n",
    "    retval, frame = g_camera.read()\n",
    "    \n",
    "    ret, frame = g_camera.read()\n",
    "    \n",
    "    #image = get_file_content('./image.jpg')\n",
    "\n",
    "    \"\"\" 2.Call gesture recognition \"\"\"\n",
    "    raw = str(client.gesture(image_widget.value))\n",
    "    text = demjson.decode(raw)\n",
    "    try:\n",
    "        res = text['result'][0]['classname']\n",
    "    except:\n",
    "        print('Result:nothing')\n",
    "        # 1 dst 2 verbal content 3 coordinate 4 5 frnot size 6 color 7 thickness 8 line type\n",
    "#       cv2.putText(frame, '未识别', (250,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,200), 2, cv2.LINE_AA) #只能显示英文\n",
    "        img = cv2ImgAddText(frame, \"unidentification\", 250, 30, (0, 0 , 255), 30)\n",
    "    else:\n",
    "        print('Result:' + hand[res])\n",
    "        #cv2.putText(frame, hand[res], (250,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "        img = cv2ImgAddText(frame, hand[res], 250, 30, (0, 255 , 0), 30)\n",
    "\n",
    "    image_widget.value = bgr8_to_jpeg(img)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
